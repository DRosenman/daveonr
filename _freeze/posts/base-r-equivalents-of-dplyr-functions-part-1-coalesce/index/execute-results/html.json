{
  "hash": "904503fdf88ae7e70fb475bb4743a13a",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Base R Equivalents of dplyr Functions Part 1 - coalesce\"\nauthor: \"Dave Rosenman\"\ndate: \"2024-05-16\"\ncategories: [R, code, tidyverse, dplyr]\n#image: \"image.jpg\"\n---\n\n\n\n\nThe dplyr `coalesce` function is incredibly useful and similar to the SQL `COALESCE` function. Given a set of vectors, it finds and keeps the first non-`NA` value at each position. For example, the following code returns the vector c(1, 2, 3, 4).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\ncoalesce(c(1, NA, 3, NA), c(2, 2, 4, 4))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1 2 3 4\n```\n\n\n:::\n:::\n\n\n* At position 1, the first non-`NA` value is 1 (from the first vector).\n* At position 2, the first non-`NA` value is 2 (from the second vector, because the value at position 2 in the first vector is NA).\n* At position 3, the first non-`NA` value is 3 (from the first vector).\n* Finally, at position 4, the first non-`NA` value is 4 (from the second vector, because the value at position 4 in the first vector is NA).\n\nThe `coalesce` function is not limited to two vectors. You can use as many vectors as you'd like.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncoalesce(c(1, 2, NA, NA), c(3, 3, 3, NA), c(4, 4, 4, 4))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1 2 3 4\n```\n\n\n:::\n:::\n\n\nThe vectors must be of equal length or length 1. Vectors of length 1 will be recycled. The following:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncoalesce(c(1, NA, NA, 5), 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1 3 3 5\n```\n\n\n:::\n:::\n\n\nIs equivalent to:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndplyr::coalesce(c(1, NA, NA, 5), c(3, 3, 3, 3))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1 3 3 5\n```\n\n\n:::\n:::\n\n\nI most often use `coalesce` to replace all `NA` values in a vector with a single value. For example, the following code replaces all `NA` values with 0:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncoalesce(c(1, NA, NA, 5, 6), 0)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1 0 0 5 6\n```\n\n\n:::\n:::\n\n\nHere are two alternative ways to do the same thing.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyr)\nreplace_na(c(1, NA, NA, 5, 6), 0) # this function is in the tidyr package\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1 0 0 5 6\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- c(1, NA, NA, 5, 6)\nifelse(is.na(x), 0, x)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1 0 0 5 6\n```\n\n\n:::\n:::\n\n\nOf the three options I have shown so far, I prefer `coalesce` and `replace_na`. (`coalesce` is a more general version of `replace_na`; `replace_na` takes a vector and a single value to replace the `NA` values in that vector with). If you want to go outside of base R and the tidyverse, `data.table::fcoalesce` is a much faster version of `dplyr::coalesce`.\n\nLet's compare the speeds!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(microbenchmark)\nlibrary(data.table)\nset.seed(11)\nx <- 1:10^7\nx[sample(1:10^7, size = 10^6, replace = FALSE)] <- NA\nmicrobenchmark(\n  fcoalesce(x, 0L),\n  coalesce(x, 0L),\n  replace_na(x, 0L),\n  ifelse(is.na(x), 0L, x),\n  times = 5\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nUnit: milliseconds\n                    expr      min       lq      mean   median       uq      max\n        fcoalesce(x, 0L)  16.3749  16.5654  19.12494  17.3630  17.6809  27.6405\n         coalesce(x, 0L) 343.9034 347.0792 377.56370 356.1268 365.5551 475.1540\n       replace_na(x, 0L)  43.2243  44.5733  63.38044  48.5045  69.4544 111.1457\n ifelse(is.na(x), 0L, x) 194.8981 207.7833 224.60976 230.3110 235.5494 254.5070\n neval\n     5\n     5\n     5\n     5\n```\n\n\n:::\n:::\n\n\n`data.table:fcoalesce` is the winner in terms of speed, followed by `replace_na`. I still tend to use `coalesce` for replacing all `NA` values in a vector with a single, specific value. I am the only person on my work team who uses R, but my team members use SQL and recognize the name `coalesce` in my code.  For small to medium-sized vectors, each function runs super quickly. Also, of the four methods above, `coalesce` and `fcoalesce` are the most general, since they are not limited to replacing all `NA` values with a single value.\n\nIs there a base R equivalent to `dplyr::coalesce`? No. But we can easily create one using just base R code.\n\nTo think about how we would do that, let's start with two vectors:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- c(1, 2, NA, NA)\ny <- c(2, 2, 3, NA)\ncoalesce(x, y)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1]  1  2  3 NA\n```\n\n\n:::\n:::\n\n\nHow could we get the same results using the `ifelse` function? It's simple. We return the value in `y` when the value in `x` is `NA`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nifelse(is.na(x), y, x)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1]  1  2  3 NA\n```\n\n\n:::\n:::\n\n\nThat's simple enough. But what if we want to use three vectors?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nz <- c(4, 4, 4, 4)\ncoalesce(x, y, z)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1 2 3 4\n```\n\n\n:::\n:::\n\n\nWe can start with our code from the case where we used two vectors.\n\n\n::: {.cell}\n\n```{.r .cell-code}\noutput_step_1 <- ifelse(is.na(x), y, x)\n```\n:::\n\n\nWhen both `x` and `y` are `NA` (when `ifelse(is.na(x), y, x)` gives us `NA`), we want to use what is in z. Otherwise, we want to keep the results from step 1 above.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nifelse(is.na(output_step_1), z, output_step_1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1 2 3 4\n```\n\n\n:::\n:::\n\n\nThat worked! But what if we want to generalize this to any number of input vectors? We can use the base R function `Reduce`. For our case where we used `x`, `y`, and `z`, we could do:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n Reduce(function(x, y) ifelse(is.na(x), y, x), list(x, y, z))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1 2 3 4\n```\n\n\n:::\n:::\n\n\n`Reduce(f, list(x, y, z))`, where `f` is a function of two variables, is the equivalent of `f(f(x, y), z)`. And `Reduce(f, list(x, y, z, a))` is equivalent to `f(f(f(x, y), z), a)`. The Reduce function is used to iteratively apply a function to elements of a list, reducing it to a single value. It takes a function with two parameters and applies it to the first two elements of the list, then applies the same function to the result and the next element, and so on, until all elements are combined into a single value.\n\nTo use `Reduce` to mimic `coalesce(x, y, z, ...)`, we need to apply the logic `f <- function(x, y) { ifelse(is.na(x), y, x)}` over and over starting from left to right. In other words, for three vectors x, y, and z, we need to do:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nf <- function(x, y) {\n  ifelse(is.na(x), y, x)\n}\nf(f(x, y), z)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1 2 3 4\n```\n\n\n:::\n:::\n\n\nWhich is equivalent to\n\n\n::: {.cell}\n\n```{.r .cell-code}\nReduce(f, list(x, y, z))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1 2 3 4\n```\n\n\n:::\n:::\n\n\nSo a very simple base R function equivalent to the `coalesce` function is:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncoalesce_base_r <- function(...) {\n  args <- list(...)\n  Reduce(function(x, y) ifelse(is.na(x), y, x), args)\n}\n```\n:::\n\n\nLet's see if it produces identical results to `dplyr::coalesce`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(11)\nx <- 1:10^7\ny <- 1:10^7\nx[sample(1:10^7, size = 10^6, replace = FALSE)] <- NA\ny[sample(1:10^7, size = 10^6, replace = FALSE)] <- NA\nz <- 1L\n\ndplyr_result <- coalesce(x, y, z)\nbase_r_result <- coalesce_base_r(x, y, z)\nidentical(dplyr_result, base_r_result)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] TRUE\n```\n\n\n:::\n:::\n\n\nWe get identical results!\n\nLet's compare the speed:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmicrobenchmark(coalesce(x, y, z), coalesce_base_r(x, y, z), times = 5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nUnit: milliseconds\n                     expr      min       lq     mean   median       uq      max\n        coalesce(x, y, z) 376.6042 392.5365 416.4361 428.5157 434.7934 449.7308\n coalesce_base_r(x, y, z) 418.2767 431.8829 463.2052 479.6486 485.1584 501.0595\n neval\n     5\n     5\n```\n\n\n:::\n:::\n\n\nOur base R version of `coalesce` is almost identical in speed dplyr's!\n\nBut our function contains some flaws. dplyr's `coalesce` function forces the vectors passed to it to either be of the same length or be of length 1. If we try:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncoalesce(c(1, 2, 3, NA, 6), c(4, 5))\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError in `coalesce()`:\n! Can't recycle `..1` (size 5) to match `..2` (size 2).\n```\n\n\n:::\n:::\n\n\nWe get an error, since the first vector has length 5 and the second has length 2.\n\n\nHere's a better base R version of `coalesce`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncoalesce_base <- function(...) {\n  args <- list(...)\n  \n  # Check for NULL, zero-length vectors, and collect lengths\n  lengths <- sapply(args, function(x) {\n    if (is.null(x) || length(x) == 0) {\n      stop(\"Arguments must not be NULL or zero-length vectors\")\n    }\n    length(x)\n  })\n  \n  # Determine the maximum length\n  max_length <- max(lengths)\n  \n  # Check if lengths are consistent. \n  # Only allow vectors of length equal to max length or length of 1\n  if (any(lengths != max_length & lengths != 1)) {\n    stop(\"All arguments must have the same length, \n         except for vectors of length 1 which can be recycled\")\n  }\n  \n  # Use Reduce with ifelse to coalesce\n  Reduce(function(x, y) ifelse(is.na(x), y, x), args)\n}\n\n# Example usage:\nv1 <- c(NA, 2, NA, 4, NA)\nv2 <- c(1, NA, 3, NA, NA)\nv3 <- 0\n\ncoalesce_base(v1, v2, v3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1 2 3 4 0\n```\n\n\n:::\n:::\n\n\nAgain, let's compare the speed of our function to `dplyr::coalesce` and `data.table::fcoalesce`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmicrobenchmark(fcoalesce(x, y, z),\n               coalesce(x, y, z), \n               coalesce_base_r(x, y, z), \n               times = 5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nUnit: milliseconds\n                     expr      min       lq      mean   median       uq\n       fcoalesce(x, y, z)  19.5898  20.7017  21.54968  20.9869  21.5736\n        coalesce(x, y, z) 351.6959 404.2627 416.54084 428.4123 447.8448\n coalesce_base_r(x, y, z) 438.8326 465.1925 479.04260 471.8438 491.8341\n      max neval\n  24.8964     5\n 450.4885     5\n 527.5100     5\n```\n\n\n:::\n:::\n\n\n`data.table::fcoalesce` is the clear winner when it comes to speed! Our function is almost identical in speed to `dplyr::coalesce`! \n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}